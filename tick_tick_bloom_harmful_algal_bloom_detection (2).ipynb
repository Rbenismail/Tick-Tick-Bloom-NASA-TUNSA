{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df5b44c",
   "metadata": {},
   "source": [
    "# Libraries & dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63c79c-1cd6-4fc2-aec8-2bbaac0c5a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pystac\n",
    "!pip install pystac_client\n",
    "!pip install planetary_computer\n",
    "!pip install nb_black\n",
    "!pip install odc-stac\n",
    "!pip install geopandas\n",
    "!pip install rioxarray\n",
    "!pip install loguru\n",
    "!pip install opencv-python\n",
    "!pip install geopy\n",
    "!pip install path\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea401cb-60be-49b7-8789-42e04efcd30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fda36-8616-4f44-b3c6-c78823cf5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f3ec8-c566-4f25-8672-c8448c9a355d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent.resolve() / r\"Documents\\ticktickbloom\"\n",
    "assert DATA_DIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838b565-1429-4aed-8c17-9aaa3f24e82c",
   "metadata": {},
   "source": [
    "# **metadata.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e64cc3-7be6-4848-9261-855c794f1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(DATA_DIR / \"metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69607f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802fd67-c1e7-44fe-9945-986c0013d60a",
   "metadata": {},
   "source": [
    "# **train_labels.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b18e8-e649-40b7-88a6-c0062ec2f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(DATA_DIR / \"train_labels.csv\")\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b016920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"severity\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b831ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"density\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(\n",
    "    np.log(\n",
    "        train_labels[(train_labels[\"density\"] > 0) & (train_labels[\"density\"] < 1e7)][\n",
    "            \"density\"\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_labels.corr(), annot=True, cmap=\"coolwarm\", center=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "771e704e",
   "metadata": {},
   "source": [
    "DATA_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_labels.merge(\n",
    "    metadata, how=\"left\", left_on=\"uid\", right_on=\"uid\", validate=\"1:1\"\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3045897",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\", center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4be632",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"region\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"region\"] == \"midwest\"][\"severity\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"region\"] == \"south\"][\"severity\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"region\"] == \"west\"][\"severity\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"region\"] == \"northeast\"][\"severity\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94f16b-1c65-463d-be09-f318f5c9d948",
   "metadata": {},
   "source": [
    "# **Process feature data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff3f94-be2e-4265-8c0d-82ae76adfa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "from IPython.display import Image\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277bd08-8cdf-4a33-b60e-2858f44b2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the STAC API\n",
    "import planetary_computer as pc\n",
    "from pystac_client import Client\n",
    "\n",
    "catalog = Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=pc.sign_inplace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ce122-a403-4a9b-9115-6d88eeee455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance as distance\n",
    "\n",
    "\n",
    "# get our bounding box to search latitude and longitude coordinates\n",
    "def get_bounding_box(latitude, longitude, meter_buffer=50000):\n",
    "    \"\"\"\n",
    "    Given a latitude, longitude, and buffer in meters, returns a bounding\n",
    "    box around the point with the buffer on the left, right, top, and bottom.\n",
    "\n",
    "    Returns a list of [minx, miny, maxx, maxy]\n",
    "    \"\"\"\n",
    "    distance_search = distance.distance(meters=meter_buffer)\n",
    "\n",
    "    # calculate the lat/long bounds based on ground distance\n",
    "    # bearings are cardinal directions to move (south, west, north, and east)\n",
    "    min_lat = distance_search.destination((latitude, longitude), bearing=180)[0]\n",
    "    min_long = distance_search.destination((latitude, longitude), bearing=270)[1]\n",
    "    max_lat = distance_search.destination((latitude, longitude), bearing=0)[0]\n",
    "    max_long = distance_search.destination((latitude, longitude), bearing=90)[1]\n",
    "\n",
    "    return [min_long, min_lat, max_long, max_lat]\n",
    "\n",
    "\n",
    "# get our date range to search, and format correctly for query\n",
    "def get_date_range(date, time_buffer_days=15):\n",
    "    \"\"\"Get a date range to search for in the planetary computer based\n",
    "    on a sample's date. The time range will include the sample date\n",
    "    and time_buffer_days days prior\n",
    "\n",
    "    Returns a string\"\"\"\n",
    "    datetime_format = \"%Y-%m-%dT\"\n",
    "    range_start = pd.to_datetime(date) - timedelta(days=time_buffer_days)\n",
    "    date_range = f\"{range_start.strftime(datetime_format)}/{pd.to_datetime(date).strftime(datetime_format)}\"\n",
    "\n",
    "    return date_range\n",
    "\n",
    "\n",
    "def crop_sentinel_image(item, bounding_box):\n",
    "    \"\"\"\n",
    "    Given a STAC item from Sentinel-2 and a bounding box tuple in the format\n",
    "    (minx, miny, maxx, maxy), return a cropped portion of the item's visual\n",
    "    imagery in the bounding box.\n",
    "\n",
    "    Returns the image as a numpy array with dimensions (color band, height, width)\n",
    "    \"\"\"\n",
    "    (minx, miny, maxx, maxy) = bounding_box\n",
    "\n",
    "    image = rioxarray.open_rasterio(pc.sign(item.assets[\"visual\"].href)).rio.clip_box(\n",
    "        minx=minx,\n",
    "        miny=miny,\n",
    "        maxx=maxx,\n",
    "        maxy=maxy,\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    return image.to_numpy()\n",
    "\n",
    "\n",
    "def crop_landsat_image(item, bounding_box):\n",
    "    \"\"\"\n",
    "    Given a STAC item from Landsat and a bounding box tuple in the format\n",
    "    (minx, miny, maxx, maxy), return a cropped portion of the item's visual\n",
    "    imagery in the bounding box.\n",
    "\n",
    "    Returns the image as a numpy array with dimensions (color band, height, width)\n",
    "    \"\"\"\n",
    "    (minx, miny, maxx, maxy) = bounding_box\n",
    "\n",
    "    image = odc.stac.stac_load(\n",
    "        [pc.sign(item)], bands=[\"red\", \"green\", \"blue\"], bbox=[minx, miny, maxx, maxy]\n",
    "    ).isel(time=0)\n",
    "    image_array = image[[\"red\", \"green\", \"blue\"]].to_array().to_numpy()\n",
    "\n",
    "    # normalize to 0 - 255 values\n",
    "    image_array = cv2.normalize(image_array, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "# Refactor our process from above into functions\n",
    "# Refactor our process from above into functions\n",
    "def select_best_item(items, date, latitude, longitude):\n",
    "    \"\"\"\n",
    "    Select the best satellite item given a sample's date, latitude, and longitude.\n",
    "    If any Sentinel-2 imagery is available, returns the closest sentinel-2 image by\n",
    "    time. Otherwise, returns the closest Landsat imagery.\n",
    "\n",
    "    Returns a tuple of (STAC item, item platform name, item date)\n",
    "    \"\"\"\n",
    "    # get item details\n",
    "    item_details = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"datetime\": item.datetime.strftime(\"%Y-%m-%d\"),\n",
    "                \"platform\": item.properties[\"platform\"],\n",
    "                \"min_long\": item.bbox[0],\n",
    "                \"max_long\": item.bbox[2],\n",
    "                \"min_lat\": item.bbox[1],\n",
    "                \"max_lat\": item.bbox[3],\n",
    "                \"item_obj\": item,\n",
    "            }\n",
    "            for item in items\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # filter to items that contain the point location, or return None if none contain the point\n",
    "    item_details[\"contains_sample_point\"] = (\n",
    "        (item_details.min_lat < latitude)\n",
    "        & (item_details.max_lat > latitude)\n",
    "        & (item_details.min_long < longitude)\n",
    "        & (item_details.max_long > longitude)\n",
    "    )\n",
    "    item_details = item_details[item_details[\"contains_sample_point\"] == True]\n",
    "    if len(item_details) == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "    # add time difference between each item and the sample\n",
    "    item_details[\"time_diff\"] = pd.to_datetime(date) - pd.to_datetime(\n",
    "        item_details[\"datetime\"]\n",
    "    )\n",
    "\n",
    "    # if we have sentinel-2, filter to sentinel-2 images only\n",
    "    item_details[\"sentinel\"] = item_details.platform.str.lower().str.contains(\n",
    "        \"sentinel\"\n",
    "    )\n",
    "    if item_details[\"sentinel\"].any():\n",
    "        item_details = item_details[item_details[\"sentinel\"] == True]\n",
    "\n",
    "        # return the closest imagery by time\n",
    "        listitems = item_details.sort_values(by=\"time_diff\", ascending=True)\n",
    "\n",
    "        for i in range(len(listitems)):\n",
    "            cloud_coverage = listitems.iloc[i, 6].properties[\"eo:cloud_cover\"]\n",
    "            shadow_pixels = listitems.iloc[i, 6].properties[\n",
    "                \"s2:cloud_shadow_percentage\"\n",
    "            ]\n",
    "            no_pixel_data = listitems.iloc[i, 6].properties[\n",
    "                \"s2:nodata_pixel_percentage\"\n",
    "            ]\n",
    "            degraded_msi_data_percentage = listitems.iloc[i, 6].properties[\n",
    "                \"s2:degraded_msi_data_percentage\"\n",
    "            ]\n",
    "            if (\n",
    "                no_pixel_data < 10\n",
    "                and cloud_coverage < 10\n",
    "                and shadow_pixels < 10\n",
    "                and degraded_msi_data_percentage < 10\n",
    "            ):\n",
    "                best_item = listitems.iloc[i]\n",
    "    # if we have sentinel-2, filter to sentinel-2 images only\n",
    "    else:\n",
    "        item_details = item_details[item_details[\"landsat\"] == True]\n",
    "        listitems = item_details.sort_values(by=\"time_diff\", ascending=True)\n",
    "        for i in range(len(listitems)):\n",
    "            # return the closest imagery by time\n",
    "            cloud_coverage_land = listitems.iloc[i, 6].properties[\n",
    "                \"landsat:cloud_cover_land\"\n",
    "            ]\n",
    "            cloud_coverage = listitems.iloc[i, 6].properties[\"eo:cloud_cover\"]\n",
    "            if cloud_coverage < 10 and cloud_coverage_land < 10:\n",
    "                best_item = listitems.iloc[i]\n",
    "    return (\n",
    "        best_item[\"item_obj\"],\n",
    "        best_item[\"platform\"],\n",
    "        best_item[\"datetime\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def image_to_features(image_array):\n",
    "    \"\"\"\n",
    "    Convert an image array of the form (color band, height, width) to a\n",
    "    1-dimensional list of features. Returns a list where the first three\n",
    "    values are the averages of each color band, and the second three\n",
    "    values are the medians of each color band.\n",
    "    \"\"\"\n",
    "    averages = image_array.mean(axis=(1, 2)).tolist()\n",
    "    standard_dev = np.std(image_array, axis=(1, 2)).tolist()\n",
    "\n",
    "    return averages + standard_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fe24a-c854-49fa-8367-cdaea9fcc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_DATA_DIR = DATA_DIR.parents[0] / \"ticktickbloom/benchmark\"\n",
    "\n",
    "# save image arrays in case we want to generate more features\n",
    "IMAGE_ARRAY_DIR = BENCHMARK_DATA_DIR / \"Train\"\n",
    "IMAGE_ARRAY_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d584496",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ARRAY_DIR_TEST = BENCHMARK_DATA_DIR / \"Test\"\n",
    "IMAGE_ARRAY_DIR_TEST.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3309ff-4539-4613-8c55-320debe8a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a random subset of the training data for the benchmark\n",
    "train_subset = metadata[metadata[\"split\"] == \"train\"].sample(n=17060, random_state=2)\n",
    "test_subset = metadata[metadata[\"split\"] == \"test\"]\n",
    "# combine train subset with all test data\n",
    "metadata_subset = pd.concat([train_subset, metadata[metadata[\"split\"] == \"test\"]])\n",
    "metadata_subset.split.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798075f-07db-45c1-b369-cb75a1c230b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "from PIL import Image as PILImage\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_images(row):\n",
    "    pass\n",
    "    # check if we've already saved the selected image array\n",
    "    image_array_pth = IMAGE_ARRAY_DIR / f\"{row.uid}.npy\"\n",
    "\n",
    "    if image_array_pth.exists():\n",
    "        with open(image_array_pth, \"rb\") as f:\n",
    "            image_array = np.load(f)\n",
    "\n",
    "    # search and load the image array if not\n",
    "    else:\n",
    "        try:\n",
    "            ## QUERY STAC API\n",
    "            # get query ranges for location and date\n",
    "            search_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=50000\n",
    "            )\n",
    "            date_range = get_date_range(row.date, time_buffer_days=15)\n",
    "\n",
    "            # search the planetary computer\n",
    "            search = catalog.search(\n",
    "                collections=[\"sentinel-2-l2a\", \"landsat-c2-l2\"],\n",
    "                bbox=search_bbox,\n",
    "                datetime=date_range,\n",
    "            )\n",
    "            items = [item for item in search.get_all_items()]\n",
    "\n",
    "            ## GET BEST IMAGE\n",
    "            if len(items) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                best_item, item_platform, item_date = select_best_item(\n",
    "                    items, row.date, row.latitude, row.longitude\n",
    "                )\n",
    "                # add to dictionary tracking best items\n",
    "                selected_items[row.uid] = {\n",
    "                    \"item_object\": best_item,\n",
    "                    \"item_platform\": item_platform,\n",
    "                    \"item_date\": item_date,\n",
    "                }\n",
    "\n",
    "            ## CONVERT TO FEATURES\n",
    "            # get small bbox just for features\n",
    "            feature_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=3000\n",
    "            )\n",
    "\n",
    "            # crop the image\n",
    "            if \"sentinel\" in item_platform.lower():\n",
    "                image_array = crop_sentinel_image(best_item, feature_bbox)\n",
    "            else:\n",
    "                image_array = crop_landsat_image(best_item, feature_bbox)\n",
    "\n",
    "            # save image array so we don't have to rerun\n",
    "            image = np.transpose(image_array, axes=[1, 2, 0]).astype(np.uint8)\n",
    "            # selected_items[row.uid] = {\"image_array\": image_array}\n",
    "            imageio.imwrite(IMAGE_ARRAY_DIR / f\"{row.uid}.png\", image)\n",
    "\n",
    "        # keep track of any that ran into errors without interrupting the process\n",
    "        except:\n",
    "            errored_ids.append(row.uid)\n",
    "    return \"ok\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fb4eb2b",
   "metadata": {},
   "source": [
    "# Import train & test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d1532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "from PIL import Image as PILImage\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# this cell takes a LONG time because it iterates over all data!\n",
    "\n",
    "# save outputs in dictionaries\n",
    "selected_items = {}\n",
    "selected_images = {}\n",
    "features_dict = {}\n",
    "errored_ids = []\n",
    "found_images = 0\n",
    "bestitemselected = 0\n",
    "\n",
    "for row in tqdm(train_subset.itertuples(), total=len(train_subset)):\n",
    "    image_array_pth = IMAGE_ARRAY_DIR / f\"{row.uid}.npy\"\n",
    "\n",
    "    if image_array_pth.exists():\n",
    "        with open(image_array_pth, \"rb\") as f:\n",
    "            image_array = np.load(f)\n",
    "\n",
    "    # search and load the image array if not\n",
    "    else:\n",
    "        try:\n",
    "            ## QUERY STAC API\n",
    "            # get query ranges for location and date\n",
    "            search_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=50000\n",
    "            )\n",
    "            date_range = get_date_range(row.date, time_buffer_days=15)\n",
    "\n",
    "            # search the planetary computer\n",
    "            search = catalog.search(\n",
    "                collections=[\"sentinel-2-l2a\", \"landsat-c2-l2\"],\n",
    "                bbox=search_bbox,\n",
    "                datetime=date_range,\n",
    "            )\n",
    "            items = [item for item in search.get_all_items()]\n",
    "\n",
    "            ## GET BEST IMAGE\n",
    "            if len(items) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                best_item, item_platform, item_date = select_best_item(\n",
    "                    items, row.date, row.latitude, row.longitude\n",
    "                )\n",
    "                # add to dictionary tracking best items\n",
    "                selected_items[row.uid] = {\n",
    "                    \"item_object\": best_item,\n",
    "                    \"item_platform\": item_platform,\n",
    "                    \"item_date\": item_date,\n",
    "                }\n",
    "\n",
    "            ## CONVERT TO FEATURES\n",
    "            # get small bbox just for features\n",
    "            feature_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=3000\n",
    "            )\n",
    "\n",
    "            # crop the image\n",
    "            if \"sentinel\" in item_platform.lower():\n",
    "                image_array = crop_sentinel_image(best_item, feature_bbox)\n",
    "            else:\n",
    "                image_array = crop_landsat_image(best_item, feature_bbox)\n",
    "\n",
    "            # save image array so we don't have to rerun\n",
    "            image = np.transpose(image_array, axes=[1, 2, 0]).astype(np.uint8)\n",
    "            # selected_items[row.uid] = {\"image_array\": image_array}\n",
    "            imageio.imwrite(IMAGE_ARRAY_DIR / f\"{row.uid}.png\", image)\n",
    "\n",
    "        # keep track of any that ran into errors without interrupting the process\n",
    "        except:\n",
    "            errored_ids.append(row.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "from PIL import Image as PILImage\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# this cell takes a LONG time because it iterates over all data!\n",
    "\n",
    "# save outputs in dictionaries\n",
    "selected_items_test = {}\n",
    "selected_images_test = {}\n",
    "features_dict_test = {}\n",
    "errored_ids_test = []\n",
    "found_images_test = 0\n",
    "bestitemselected_test = 0\n",
    "\n",
    "for row in tqdm(test_subset.itertuples(), total=len(test_subset)):\n",
    "    image_array_pth = IMAGE_ARRAY_DIR_TEST / f\"{row.uid}.npy\"  ##????????\n",
    "\n",
    "    if image_array_pth.exists():\n",
    "        with open(image_array_pth, \"rb\") as f:\n",
    "            image_array = np.load(f)\n",
    "\n",
    "    # search and load the image array if not\n",
    "    else:\n",
    "        try:\n",
    "            ## QUERY STAC API\n",
    "            # get query ranges for location and date\n",
    "            search_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=50000\n",
    "            )\n",
    "            date_range = get_date_range(row.date, time_buffer_days=15)\n",
    "\n",
    "            # search the planetary computer\n",
    "            search = catalog.search(\n",
    "                collections=[\"sentinel-2-l2a\", \"landsat-c2-l2\"],\n",
    "                bbox=search_bbox,\n",
    "                datetime=date_range,\n",
    "            )\n",
    "            items = [item for item in search.get_all_items()]\n",
    "\n",
    "            ## GET BEST IMAGE\n",
    "            if len(items) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                best_item, item_platform, item_date = select_best_item(\n",
    "                    items, row.date, row.latitude, row.longitude\n",
    "                )\n",
    "                # add to dictionary tracking best items\n",
    "                selected_items[row.uid] = {\n",
    "                    \"item_object\": best_item,\n",
    "                    \"item_platform\": item_platform,\n",
    "                    \"item_date\": item_date,\n",
    "                }\n",
    "\n",
    "            ## CONVERT TO FEATURES\n",
    "            # get small bbox just for features\n",
    "            feature_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=3000\n",
    "            )\n",
    "\n",
    "            # crop the image\n",
    "            if \"sentinel\" in item_platform.lower():\n",
    "                image_array = crop_sentinel_image(best_item, feature_bbox)\n",
    "            else:\n",
    "                image_array = crop_landsat_image(best_item, feature_bbox)\n",
    "\n",
    "            # save image array so we don't have to rerun\n",
    "            image = np.transpose(image_array, axes=[1, 2, 0]).astype(np.uint8)\n",
    "            # selected_items[row.uid] = {\"image_array\": image_array}\n",
    "            imageio.imwrite(IMAGE_ARRAY_DIR_TEST / f\"{row.uid}.png\", image)\n",
    "\n",
    "        # keep track of any that ran into errors without interrupting the process\n",
    "        except:\n",
    "            errored_ids.append(row.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f309b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "from PIL import Image\n",
    "\n",
    "paths = sorted(list(IMAGE_ARRAY_DIR.glob(\"*.png\")))\n",
    "path_list = os.path.split(paths[0])\n",
    "id = path_list[1][:4]\n",
    "\n",
    "im = Image.open(path_list[0] + \"\\\\\" + path_list[1])\n",
    "np.asarray(im).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import os\n",
    "import stat\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4350d63",
   "metadata": {},
   "source": [
    "# 1st approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfbe8595",
   "metadata": {},
   "source": [
    "### creating features, spectral data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "137125d3",
   "metadata": {},
   "source": [
    "4D tensors will be used as input; each channel have the information of a choosen spectral index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdf87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for row in tqdm(train_subset.itertuples(), total=len(train_subset)):\n",
    "    ## QUERY STAC API\n",
    "    # get query ranges for location and date\n",
    "    search_bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=50000)\n",
    "    date_range = get_date_range(row.date, time_buffer_days=60)\n",
    "\n",
    "    # search the planetary computer\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        bbox=search_bbox,\n",
    "        datetime=date_range,\n",
    "    )\n",
    "    items = [item for item in search.get_all_items()]\n",
    "\n",
    "    ## GET BEST IMAGE\n",
    "    if len(items) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            best_item, item_platform, item_date = select_best_item(\n",
    "                items, row.date, row.latitude, row.longitude\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        # add to dictionary tracking best items\n",
    "    feature_bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=3000)\n",
    "\n",
    "    (minx, miny, maxx, maxy) = feature_bbox\n",
    "\n",
    "    try:\n",
    "        # spectral bands\n",
    "        nir = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B08\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        red = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B04\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        green = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B03\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        blue = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B02\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        n_nir = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B8A\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        red_v = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B05\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "\n",
    "        # different shapes\n",
    "        red_v = red_v.astype(np.float32)\n",
    "        red_v = transforms.Resize((605, 604))(\n",
    "            transforms.ToPILImage()(red_v.transpose())\n",
    "        )\n",
    "        red_v = np.asarray(red_v)\n",
    "\n",
    "        n_nir = n_nir.astype(np.float32)\n",
    "        n_nir = transforms.Resize((605, 604))(\n",
    "            transforms.ToPILImage()(n_nir.transpose())\n",
    "        )\n",
    "        n_nir = np.asarray(n_nir)\n",
    "\n",
    "        red = red.astype(np.float32)\n",
    "        red = transforms.Resize((605, 604))(transforms.ToPILImage()(red.transpose()))\n",
    "        red = np.asarray(red)\n",
    "\n",
    "        blue = blue.astype(np.float32)\n",
    "        blue = transforms.Resize((605, 604))(transforms.ToPILImage()(blue.transpose()))\n",
    "        blue = np.asarray(blue)\n",
    "\n",
    "        green = green.astype(np.float32)\n",
    "        green = transforms.Resize((605, 604))(\n",
    "            transforms.ToPILImage()(green.transpose())\n",
    "        )\n",
    "        green = np.asarray(green)\n",
    "\n",
    "        nir = n_nir.astype(np.float32)\n",
    "        nir = transforms.Resize((605, 604))(transforms.ToPILImage()(nir.transpose()))\n",
    "        nir = np.asarray(nir)\n",
    "\n",
    "        # spectral indices\n",
    "        NDVI = (nir - red) / (nir + red)\n",
    "        NDCI = (red_v - red) / (red_v + red)\n",
    "        B8AB4 = (n_nir - red) / (n_nir + red)\n",
    "        B3B2 = (green - blue) / (green + blue)\n",
    "        im = np.stack((NDVI, NDCI, B8AB4, B3B2), axis=-1)\n",
    "        path = \"Train_tensors/\" + row.uid + \".npy\"\n",
    "        np.save(DATA_DIR / path, im.T)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(test_subset.itertuples(), total=len(test_subset)):\n",
    "    ## QUERY STAC API\n",
    "    # get query ranges for location and date\n",
    "    search_bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=50000)\n",
    "    date_range = get_date_range(row.date, time_buffer_days=15)\n",
    "\n",
    "    # search the planetary computer\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        bbox=search_bbox,\n",
    "        datetime=date_range,\n",
    "    )\n",
    "    items = [item for item in search.get_all_items()]\n",
    "\n",
    "    ## GET BEST IMAGE\n",
    "    if len(items) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            best_item, item_platform, item_date = select_best_item(\n",
    "                items, row.date, row.latitude, row.longitude\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        # add to dictionary tracking best items\n",
    "    feature_bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=3000)\n",
    "\n",
    "    (minx, miny, maxx, maxy) = feature_bbox\n",
    "\n",
    "    try:\n",
    "        # spectral bands\n",
    "        nir = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B08\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        red = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B04\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        green = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B03\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        blue = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B02\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        n_nir = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B8A\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "        red_v = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B05\"].href)).rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "        ).to_numpy()\n",
    "\n",
    "        # different shapes\n",
    "        red_v = red_v.astype(np.float32)\n",
    "        red_v = transforms.Resize((605, 604))(\n",
    "            transforms.ToPILImage()(red_v.transpose())\n",
    "        )\n",
    "        red_v = np.asarray(red_v)\n",
    "\n",
    "        n_nir = n_nir.astype(np.float32)\n",
    "        n_nir = transforms.Resize((605, 604))(\n",
    "            transforms.ToPILImage()(n_nir.transpose())\n",
    "        )\n",
    "        n_nir = np.asarray(n_nir)\n",
    "\n",
    "        red = red.astype(np.float32)\n",
    "        red = transforms.Resize((605, 604))(transforms.ToPILImage()(red.transpose()))\n",
    "        red = np.asarray(red)\n",
    "\n",
    "        blue = blue.astype(np.float32)\n",
    "        blue = transforms.Resize((605, 604))(transforms.ToPILImage()(blue.transpose()))\n",
    "        blue = np.asarray(blue)\n",
    "\n",
    "        green = green.astype(np.float32)\n",
    "        green = transforms.Resize((605, 604))(\n",
    "            transforms.ToPILImage()(green.transpose())\n",
    "        )\n",
    "        green = np.asarray(green)\n",
    "\n",
    "        nir = n_nir.astype(np.float32)\n",
    "        nir = transforms.Resize((605, 604))(transforms.ToPILImage()(nir.transpose()))\n",
    "        nir = np.asarray(nir)\n",
    "\n",
    "        # spectral indices\n",
    "        NDVI = (nir - red) / (nir + red)\n",
    "        NDCI = (red_v - red) / (red_v + red)\n",
    "        B8AB4 = (n_nir - red) / (n_nir + red)\n",
    "        B3B2 = (green - blue) / (green + blue)\n",
    "        im = np.stack((NDVI, NDCI, B8AB4, B3B2), axis=-1)\n",
    "        path = \"Test_tensors/\" + row.uid + \".npy\"\n",
    "        np.save(DATA_DIR / path, im.T)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "035b55ca",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec038901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dir = DATA_DIR / \"Train_tensors\"\n",
    "paths = sorted(list(dir.glob(\"*.npy\")))\n",
    "test_size = int(0.2 * len(paths))\n",
    "val_paths = random.sample(paths, test_size)\n",
    "train_paths = [x for x in paths if x not in val_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.tensor_paths = paths\n",
    "\n",
    "    def load_tensor(self, index: int):\n",
    "        tensor_path = self.tensor_paths[index]\n",
    "        return np.load(tensor_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.load_tensor(index)\n",
    "        tensor_path = self.tensor_paths[index]\n",
    "        path_list = os.path.split(tensor_path)\n",
    "        id = path_list[1][:4]\n",
    "        y = train_labels[train_labels.uid == id][\"severity\"][\n",
    "            train_labels[train_labels.uid == id].index[0]\n",
    "        ]\n",
    "        return img, y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_paths)\n",
    "val_dataset = Dataset(val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=4, num_workers=0, shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=val_dataset, batch_size=4, num_workers=0, shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f633c26",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4e424c3",
   "metadata": {},
   "source": [
    "Resnet50 doesn't work with 4 channels :: to adress thsi issue we can add a conv layer before resnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61d4d5e6",
   "metadata": {},
   "source": [
    "Custumized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197588c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        # Convolutional layer to reduce number of channels from 4 to 3\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=4, out_channels=3, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "\n",
    "        # Load a pre-trained ResNet50 model\n",
    "        self.resnet = models.resnet50(pretrained=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the convolutional layer\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # replace the last fully-connected layer with our own classifier\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        num_classes = 5\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        # Pass the output through the ResNet50 model\n",
    "        x = self.resnet(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48845d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel()\n",
    "# summary(model, (4, 605, 604))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58de0140",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634316c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (image, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "def test_step(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label) in enumerate(dataloader):\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, label)\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(dataloader)\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    epochs,\n",
    "):\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "\n",
    "        test_loss = test_step(model=model, dataloader=test_dataloader, loss_fn=loss_fn)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "model_result = train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=criterion,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20baf0cb",
   "metadata": {},
   "source": [
    "Not enough RAM!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab9fec84",
   "metadata": {},
   "source": [
    "# 2nd approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e826e98",
   "metadata": {},
   "source": [
    "### Creating Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this algorith will be used to extract water and algae pixels\n",
    "def otsu_binarization(image, mask=None):\n",
    "    if mask is None:\n",
    "        mask = np.full_like(image, True, dtype=bool)\n",
    "\n",
    "    pixel_values, counts = np.unique(image[mask], return_counts=True)\n",
    "    probabilities = counts / image[mask].size\n",
    "    thresholds = pixel_values[1:]\n",
    "\n",
    "    best_threshold = None\n",
    "    max_y = float(\"-inf\")\n",
    "    for index, threshold in tqdm(enumerate(thresholds, 1), total=thresholds.shape[0]):\n",
    "        pixel_value0 = pixel_values[pixel_values < threshold]\n",
    "        pixel_value1 = pixel_values[pixel_values >= threshold]\n",
    "\n",
    "        probabilities0 = probabilities[pixel_values < threshold]\n",
    "        probabilities1 = probabilities[pixel_values >= threshold]\n",
    "        w0 = probabilities0.sum()\n",
    "        w1 = probabilities1.sum()\n",
    "        mu0 = (pixel_value0 * probabilities0).sum() / w0\n",
    "        mu1 = (pixel_value1 * probabilities1).sum() / w1\n",
    "\n",
    "        u = w0 * mu0 + w1 * mu1\n",
    "        y = w0 * (mu0 - u) ** 2 + w1 * (mu1 - u) ** 2\n",
    "\n",
    "        if y > max_y:\n",
    "            best_threshold = threshold\n",
    "            max_y = y\n",
    "\n",
    "    return np.all(np.array([image >= best_threshold, mask]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing images\n",
    "def resize_images(*imgs):\n",
    "    img_shapes = [img.shape for img in imgs]\n",
    "    h, w = float(\"inf\"), float(\"inf\")\n",
    "    for shape in img_shapes:\n",
    "        h_temp, w_temp = shape\n",
    "        if h_temp < h:\n",
    "            h = h_temp\n",
    "        if w_temp < w:\n",
    "            w = w_temp\n",
    "    return (\n",
    "        cv2.resize(img, dsize=(h, w), interpolation=cv2.INTER_CUBIC) for img in imgs\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddc99c3a",
   "metadata": {},
   "source": [
    "### creating features; mean & std of selected spectral indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab45df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {}\n",
    "ids = []\n",
    "import os\n",
    "import stat\n",
    "from PIL import Image\n",
    "\n",
    "dir = DATA_DIR / \"Train_tensors\"\n",
    "paths = sorted(list(dir.glob(\"*.npy\")))\n",
    "\n",
    "\n",
    "for row in tqdm(train_subset[945:].itertuples(), total=len(train_subset[945:])):\n",
    "    ## QUERY STAC API\n",
    "    # get query ranges for location and date\n",
    "    search_bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=50000)\n",
    "    date_range = get_date_range(row.date, time_buffer_days=60)\n",
    "\n",
    "    # search the planetary computer\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-2-l2a\"],\n",
    "        bbox=search_bbox,\n",
    "        datetime=date_range,\n",
    "    )\n",
    "    items = [item for item in search.get_all_items()]\n",
    "\n",
    "    ## GET BEST IMAGE\n",
    "    if len(items) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            best_item, item_platform, item_date = select_best_item(\n",
    "                items, row.date, row.latitude, row.longitude\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        # add to dictionary tracking best items\n",
    "    feature_bbox = get_bounding_box(row.latitude, row.longitude, meter_buffer=3000)\n",
    "\n",
    "    (minx, miny, maxx, maxy) = feature_bbox\n",
    "\n",
    "    try:\n",
    "        # spectral bands\n",
    "        nir = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B08\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "        red = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B04\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "        green = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B03\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "        blue = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B02\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "        n_nir = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B8A\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "        red_v = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B05\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "\n",
    "        b11 = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B11\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "\n",
    "        b06 = (\n",
    "            rioxarray.open_rasterio(pc.sign(best_item.assets[\"B06\"].href))\n",
    "            .rio.clip_box(\n",
    "                minx=minx,\n",
    "                miny=miny,\n",
    "                maxx=maxx,\n",
    "                maxy=maxy,\n",
    "                crs=\"EPSG:4326\",\n",
    "            )\n",
    "            .to_numpy()[0]\n",
    "        )\n",
    "\n",
    "        # resizing\n",
    "        b11, blue, n_nir, red_v, b06, red, nir, green = resize_images(\n",
    "            b11, blue, n_nir, red_v, b06, red, nir, green\n",
    "        )\n",
    "\n",
    "        # spectral indices\n",
    "        NDVI = (nir - red) / (nir + red)\n",
    "        NDCI = (red_v - red) / (red_v + red)\n",
    "        B8AB4 = (n_nir - red) / (n_nir + red)\n",
    "        B3B2 = (green - blue) / (green + blue)\n",
    "        swi = (red_v - b11) / (red_v + b11)\n",
    "        abdi = (b06 - red - (nir - red) * (740.5 - 15) / (832.8 - 15)) - (\n",
    "            red - 0.5 * green\n",
    "        )\n",
    "\n",
    "        # water & algae extraction\n",
    "        extracted_water = otsu_binarization(swi)\n",
    "        extracted_algae = otsu_binarization(abdi, extracted_water)\n",
    "\n",
    "        f1, f2 = [np.mean(NDVI)], [np.std(NDVI)]\n",
    "        f3, f4 = [np.mean(NDCI)], [np.std(NDCI)]\n",
    "        f5, f6 = [np.mean(B8AB4)], [np.std(B8AB4)]\n",
    "        f7, f8 = [np.mean(B3B2)], [np.std(B3B2)]\n",
    "        f9, f10 = [np.mean(extracted_algae)], [np.std(extracted_algae)]\n",
    "        features = f1 + f2 + f3 + f4 + f5 + f6 + f7 + f8 + f9 + f10\n",
    "\n",
    "        features_dict[row.uid] = [row.uid] + features\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec37f8b1",
   "metadata": {},
   "source": [
    "### Storing data in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write to csv file\n",
    "with open('data.csv', 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=features_dict.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows([dict(zip(features_dict.keys(), t)) for t in zip(*features_dict.values())])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b494843",
   "metadata": {},
   "source": [
    "### dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e70f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring features into a dataframe\n",
    "train_set = pd.DataFrame(features_dict).T\n",
    "train_set.columns = [\n",
    "    \"uid\",\n",
    "    \"NDVI_average\",\n",
    "    \"NDCI_average\",\n",
    "    \"B8AB4_average\",\n",
    "    \"B3B2_average\",\n",
    "    \"algae_average\",\n",
    "    \"NDVI_std\",\n",
    "    \"NDCI_std\",\n",
    "    \"B8AB4_std\",\n",
    "    \"B3B2_std\",\n",
    "    \"algae_std\"\n",
    "]\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = train_set.merge(\n",
    "    train_labels, how=\"left\", left_on=\"uid\", right_on=\"uid\", validate=\"1:1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "104c5001",
   "metadata": {},
   "source": [
    "### Machine learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.drop([\"density\", \"severity\"], axis=1, inplace=False)\n",
    "y = dataframe[\"severity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e09db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae064aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f09bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fillna(X.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_reg = pd.get_dummies(X[\"region\"])\n",
    "df = pd.concat([X, dummy_reg], axis=1)\n",
    "X = df.drop([\"uid\"], axis=1, inplace=False)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_test_northeast = X[X[\"region\"] == \"northeast\"]\n",
    "X_test_midwest = X[X[\"region\"] == \"midwest\"]\n",
    "X_test_west = X[X[\"region\"] == \"west\"]\n",
    "X_test_south = X[X[\"region\"] == \"south\"]\n",
    "\n",
    "y_test_northeast = dataframe[dataframe[\"region\"] == \"northeast\"][\"severity\"]\n",
    "y_test_midwest = dataframe[dataframe[\"region\"] == \"midwest\"][\"severity\"]\n",
    "y_test_west = dataframe[dataframe[\"region\"] == \"west\"][\"severity\"]\n",
    "y_test_south = dataframe[dataframe[\"region\"] == \"south\"][\"severity\"]\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "X_train1 = X_train.drop([\"region\"], axis=1, inplace=False)\n",
    "clf.fit(X_train1, y_train)\n",
    "\n",
    "X_test.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_northeast.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_midwest.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_west.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_south.drop(\"region\", axis=1, inplace=True)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_northeast = clf.predict(X_test_northeast)\n",
    "y_pred_midwest = clf.predict(X_test_midwest)\n",
    "y_pred_west = clf.predict(X_test_west)\n",
    "y_pred_south = clf.predict(X_test_south)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# avg_region_rmse\n",
    "avg_reg_rmse = (\n",
    "    1\n",
    "    / 4\n",
    "    * (\n",
    "        np.sqrt(mean_squared_error(y_test_northeast, y_pred_northeast))\n",
    "        + np.sqrt(mean_squared_error(y_test_midwest, y_pred_midwest))\n",
    "        + np.sqrt(mean_squared_error(y_test_west, y_pred_west))\n",
    "        + np.sqrt(mean_squared_error(y_test_south, y_pred_south))\n",
    "    )\n",
    ")\n",
    "print(\"avg_region_rmse:\", avg_reg_rmse)\n",
    "print(\"rmse_norwest:\", np.sqrt(mean_squared_error(y_test_northeast, y_pred_northeast)))\n",
    "print(\"rmse_midwest:\", np.sqrt(mean_squared_error(y_test_midwest, y_pred_midwest)))\n",
    "print(\"rmse_south:\", np.sqrt(mean_squared_error(y_test_south, y_pred_south)))\n",
    "print(\"rmse_north:\", np.sqrt(mean_squared_error(y_test_west, y_pred_west)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_test_northeast = X[X[\"region\"] == \"northeast\"]\n",
    "X_test_midwest = X[X[\"region\"] == \"midwest\"]\n",
    "X_test_west = X[X[\"region\"] == \"west\"]\n",
    "X_test_south = X[X[\"region\"] == \"south\"]\n",
    "\n",
    "y_test_northeast = dataframe[dataframe[\"region\"] == \"northeast\"][\"severity\"]\n",
    "y_test_midwest = dataframe[dataframe[\"region\"] == \"midwest\"][\"severity\"]\n",
    "y_test_west = dataframe[dataframe[\"region\"] == \"west\"][\"severity\"]\n",
    "y_test_south = dataframe[dataframe[\"region\"] == \"south\"][\"severity\"]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "X_train1 = X_train.drop([\"region\"], axis=1, inplace=False)\n",
    "clf.fit(X_train1, y_train)\n",
    "\n",
    "X_test.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_northeast.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_midwest.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_west.drop(\"region\", axis=1, inplace=True)\n",
    "X_test_south.drop(\"region\", axis=1, inplace=True)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_northeast = clf.predict(X_test_northeast)\n",
    "y_pred_midwest = clf.predict(X_test_midwest)\n",
    "y_pred_west = clf.predict(X_test_west)\n",
    "y_pred_south = clf.predict(X_test_south)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# avg_region_rmse\n",
    "avg_reg_rmse = (\n",
    "    1\n",
    "    / 4\n",
    "    * (\n",
    "        np.sqrt(mean_squared_error(y_test_northeast, y_pred_northeast))\n",
    "        + np.sqrt(mean_squared_error(y_test_midwest, y_pred_midwest))\n",
    "        + np.sqrt(mean_squared_error(y_test_west, y_pred_west))\n",
    "        + np.sqrt(mean_squared_error(y_test_south, y_pred_south))\n",
    "    )\n",
    ")\n",
    "print(\"avg_region_rmse:\", avg_reg_rmse)\n",
    "print(\"rmse_norwest:\", np.sqrt(mean_squared_error(y_test_northeast, y_pred_northeast)))\n",
    "print(\"rmse_midwest:\", np.sqrt(mean_squared_error(y_test_midwest, y_pred_midwest)))\n",
    "print(\"rmse_south:\", np.sqrt(mean_squared_error(y_test_south, y_pred_south)))\n",
    "print(\"rmse_west:\", np.sqrt(mean_squared_error(y_test_west, y_pred_west)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a138b6ecd7bd97edef5ed73a611bbda83416f6746a361b8186edec2994543fd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
